{"metadata":{"language_info":{"name":"python","version":"3.9.0","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"name":"python3","display_name":"Python 3 (ipykernel)","language":"python"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\n\nimport pandas as pd\nfrom pandas.api.types import CategoricalDtype\n\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn import linear_model as lm\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport zipfile\nimport os\n\n#from ds100_utils import run_linear_regression_test\n\n# Plot settings\nplt.rcParams['figure.figsize'] = (12, 9)\nplt.rcParams['font.size'] = 12","metadata":{"trusted":true},"execution_count":2,"outputs":[],"id":"b3ef6f1e-c113-449d-a318-54c890ef03c4"},{"cell_type":"code","source":"#training_data = maybe merge the Ahmed data with the insurance?","metadata":{"trusted":true},"execution_count":3,"outputs":[],"id":"fe3b11d7-d2af-4189-98dd-240b8c9c7e34"},{"cell_type":"markdown","source":"As a good sanity check, we should at least verify that the data shape matches the description.","metadata":{},"id":"000e0cd2-3012-42c5-897a-0515e03bf11a"},{"cell_type":"code","source":"\n# 204792 observations and 62 features in training data\n#assert training_data.shape == (204792, 62)\n# 68264 observations and 61 features in test data\n#assert test_data.shape == (68264, 61)\n# Sale Price is provided in the training data\n#assert 'Sale Price' in training_data.columns.values\n# Sale Price is hidden in the test data\n#assert 'Sale Price' not in test_data.columns.values","metadata":{"trusted":true},"execution_count":4,"outputs":[],"id":"8fec0b59-9a5a-46b1-8ea3-7880809c3a8f"},{"cell_type":"markdown","source":"We're now asking ourselves some questions about the data:\n\nWho would be interested in seeing the effect of anxiety symptoms based on access to health care?\n\nWho would be...[insert some bullshit]","metadata":{},"id":"016ef308-7a0e-449c-b543-20c5d873a27d"},{"cell_type":"markdown","source":"### split training & test data","metadata":{},"id":"9db19f40-0a73-4879-adff-325a1c92dac7"},{"cell_type":"code","source":"# This makes the train-test split in this section reproducible across different runs \n# of the notebook. You do not need this line to run train_test_split in general\n\n# DO NOT CHANGE THIS LINE\nnp.random.seed(1337)\n# DO NOT CHANGE THIS LINE\n\ndef train_test_split(data):\n    data_len = data.shape[0]\n    shuffled_indices = np.random.permutation(data_len)\n    train_indices = shuffled_indices[:int(data_len//(1.25))]\n    test_indices = shuffled_indices[int(data_len//(1.25)):]\n    return data.iloc[train_indices,:], data.iloc[test_indices,:]\n     \ntrain, test = train_test_split(training_data)","metadata":{"trusted":true},"execution_count":5,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_165/4294392442.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_indices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_indices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'training_data' is not defined"],"ename":"NameError","evalue":"name 'training_data' is not defined","output_type":"error"}],"id":"8d2ab946-2edd-41d9-9d0b-e112b4af4df4"},{"cell_type":"markdown","source":"### Model fitting","metadata":{},"id":"13f788a9-f9dc-4429-82d4-5fd1b737fda5"},{"cell_type":"markdown","source":"First, we define some feature functions:","metadata":{},"id":"b6110714-73da-4856-8713-0dc02d79536d"},{"cell_type":"code","source":"def remove_outliers(data, variable, lower=-np.inf, upper=np.inf):\n    \"\"\"\n    Input:\n      data (data frame): the table to be filtered\n      variable (string): the column with numerical outliers\n      lower (numeric): observations with values lower than this will be removed\n      upper (numeric): observations with values higher than this will be removed\n    \n    Output:\n      a data frame with outliers removed\n      \n    Note: This function should not change mutate the contents of data.\n    \"\"\"  \n    data = data[data[variable] > lower]\n    data = data[data[variable] < upper]\n    return data\n\n\ndef ohe_column(data, column):\n    \"\"\"\n    One-hot-encodes roof material. New columns are of the form x0_MATERIAL.\n    \"\"\"\n    oh_enc = OneHotEncoder()\n    oh_enc.fit(data[[column]])\n    dummies = pd.DataFrame(oh_enc.transform(data[[column]]).todense(), columns=oh_enc.get_feature_names_out(),index = data.index)\n\n    return data.join(dummies)\n","metadata":{"trusted":true},"execution_count":8,"outputs":[],"id":"d4b67a6c-5896-4e02-b00c-d5680a9fdecb"},{"cell_type":"code","source":"from feature_func import *    # imports functions from Project 1A\n# run this cell to define process_data_gm and select_columns\n\ndef process_data_gm(data, pipeline_functions, prediction_col):\n    \"\"\"Process the data for a guided model.\"\"\"\n    for function, arguments, keyword_arguments in pipeline_functions:\n        if keyword_arguments and (not arguments):\n            data = data.pipe(function, **keyword_arguments)\n        elif (not keyword_arguments) and (arguments):\n            data = data.pipe(function, *arguments)\n        else:\n            data = data.pipe(function)\n    X = data.drop(columns=[prediction_col]).to_numpy()\n    y = data.loc[:, prediction_col].to_numpy()\n    return X, y","metadata":{"trusted":true},"execution_count":6,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_165/919492007.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfeature_func\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m    \u001b[0;31m# imports functions from Project 1A\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# run this cell to define process_data_gm and select_columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprocess_data_gm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpipeline_functions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_col\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m\"\"\"Process the data for a guided model.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'feature_func'"],"ename":"ModuleNotFoundError","evalue":"No module named 'feature_func'","output_type":"error"}],"id":"e610e802-bc14-4b89-a961-7386a4b99666"},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[],"id":"3f8e56a4-aeb5-490a-b60a-f54ca670baf2"}]}